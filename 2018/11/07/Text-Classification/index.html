<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="深度学习,自然语言处理," />










<meta name="description" content="用深度学习来解决大规模文本分类问题具体业务场景淘宝商品的一个典型的例子见下图，图中商品的标题是“夏装雪纺条纹短袖t恤女春半袖衣服夏天中长款大码胖mm显瘦上衣夏”。淘宝网后台是通过树形的多层的类目体系管理商品的，覆盖叶子类目数量达上万个，商品量也是10亿量级，我们是任务是根据商品标题预测其所在叶子类目，示例中商品归属的类目为“女装/女士精品&amp;gt;&amp;gt;蕾丝衫/雪纺衫”。很显然，这是一个非常典型的">
<meta name="keywords" content="深度学习,自然语言处理">
<meta property="og:type" content="article">
<meta property="og:title" content="Text-Classification">
<meta property="og:url" content="http://super1peng.xyz/2018/11/07/Text-Classification/index.html">
<meta property="og:site_name" content="大大大大碗面">
<meta property="og:description" content="用深度学习来解决大规模文本分类问题具体业务场景淘宝商品的一个典型的例子见下图，图中商品的标题是“夏装雪纺条纹短袖t恤女春半袖衣服夏天中长款大码胖mm显瘦上衣夏”。淘宝网后台是通过树形的多层的类目体系管理商品的，覆盖叶子类目数量达上万个，商品量也是10亿量级，我们是任务是根据商品标题预测其所在叶子类目，示例中商品归属的类目为“女装/女士精品&amp;gt;&amp;gt;蕾丝衫/雪纺衫”。很显然，这是一个非常典型的">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzgdnigumj30k00aj75t.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzgigwltvj30k004qt96.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzhd47jnsj30k00bggmm.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzhj51cllj30k0011t8v.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzhmjh39rj313g0gy3zq.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzhw924n3j30k00a5dg1.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzic7am5vj30k007kaaz.jpg">
<meta property="og:image" content="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzihtrtraj30k00jlwgo.jpg">
<meta property="og:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzjocq0vxj30k0069aak.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzjrgsojaj30k007utaa.jpg">
<meta property="og:image" content="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzjss4c6fj30k0020mxe.jpg">
<meta property="og:image" content="https://ws2.sinaimg.cn/large/006tNbRwgy1fwzjtvcxrkj30k000w0sq.jpg">
<meta property="og:updated_time" content="2018-11-07T08:22:08.289Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Text-Classification">
<meta name="twitter:description" content="用深度学习来解决大规模文本分类问题具体业务场景淘宝商品的一个典型的例子见下图，图中商品的标题是“夏装雪纺条纹短袖t恤女春半袖衣服夏天中长款大码胖mm显瘦上衣夏”。淘宝网后台是通过树形的多层的类目体系管理商品的，覆盖叶子类目数量达上万个，商品量也是10亿量级，我们是任务是根据商品标题预测其所在叶子类目，示例中商品归属的类目为“女装/女士精品&amp;gt;&amp;gt;蕾丝衫/雪纺衫”。很显然，这是一个非常典型的">
<meta name="twitter:image" content="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzgdnigumj30k00aj75t.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://super1peng.xyz/2018/11/07/Text-Classification/"/>





  <title>Text-Classification | 大大大大碗面</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    

  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    
    <a href="https://github.com/super1peng"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">大大大大碗面</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://super1peng.xyz/2018/11/07/Text-Classification/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="super1peng">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/nice.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大大大大碗面">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Text-Classification</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-11-07T16:01:09+08:00">
                2018-11-07
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i> 阅读总量
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="用深度学习来解决大规模文本分类问题"><a href="#用深度学习来解决大规模文本分类问题" class="headerlink" title="用深度学习来解决大规模文本分类问题"></a>用深度学习来解决大规模文本分类问题</h2><h3 id="具体业务场景"><a href="#具体业务场景" class="headerlink" title="具体业务场景"></a>具体业务场景</h3><p>淘宝商品的一个典型的例子见下图，图中商品的标题是“夏装雪纺条纹短袖t恤女春半袖衣服夏天中长款大码胖mm显瘦上衣夏”。淘宝网后台是通过树形的多层的类目体系管理商品的，覆盖叶子类目数量达上万个，商品量也是10亿量级，我们是任务是根据商品标题预测其所在叶子类目，示例中商品归属的类目为“女装/女士精品&gt;&gt;蕾丝衫/雪纺衫”。很显然，这是一个非常典型的短文本多分类问题。接下来分别会介绍下文本分类传统和深度学习的做法，最后简单梳理下实践的经验。<br><a id="more"></a></p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzgdnigumj30k00aj75t.jpg" width="50%"></p>
<h3 id="传统的文本分类问题"><a href="#传统的文本分类问题" class="headerlink" title="传统的文本分类问题"></a>传统的文本分类问题</h3><p>文本分类问题算是自然语言处理领域中一个非常经典的问题，最早就通过专家规则（Pattern）进行分类，甚至在80年代初一度发展到利用知识工程建立专家系统。</p>
<p>后来伴随着统计学习方法的发展，特别是90年代后互联网在线文本数量增长和机器学习学科的兴起，逐渐形成了一套解决大规模文本分类问题的经典玩法，这个阶段的主要套路是人工特征工程+浅层分类模型。训练文本分类器过程见下图：  </p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzgigwltvj30k004qt96.jpg" width="50%">  </p>
<p>这样整个文本分类就可以拆分成 特征工程 和 分类器 两个部分。</p>
<h4 id="特征工程"><a href="#特征工程" class="headerlink" title="特征工程"></a>特征工程</h4><p>特征工程在机器学习中往往是最耗时耗力的，但却极其的重要。抽象来讲，机器学习问题是把数据转换成信息再提炼到知识的过程，特征是“数据–&gt;信息”的过程，决定了结果的上限，而分类器是“信息–&gt;知识”的过程，则是去逼近这个上限。然而特征工程不同于分类器模型，不具备很强的通用性，往往需要结合对特征任务的理解。  </p>
<p>文本分类问题所在的自然语言领域自然也有其特有的特征处理逻辑，传统分本分类任务大部分工作也在此处。文本特征工程分位文本预处理、特征提取、文本表示三个部分，最终目的是把文本转换成计算机可理解的格式，并封装足够用于分类的信息，即很强的特征表达能力。</p>
<ul>
<li>文本处理  </li>
</ul>
<p>文本预处理过程是在文本中提取关键词表示文本的过程，中文文本处理中主要包括文本分词和去停用词两个阶段。之所以进行分词，是因为很多研究表明特征粒度为词粒度远好于字粒度，其实很好理解，因为大部分分类算法不考虑词序信息，基于字粒度显然损失了过多“n-gram”信息。</p>
<p>不同于英文的分词具有天然的空格间隔，中文的分词需要设计复杂的分词算法。传统算法主要有基于字符串匹配的正向/逆向/双向最大匹配；基于理解的句法和语义分析消歧；基于统计的互信息/CRF方法。近年来随着深度学习的应用，WordEmbedding + Bi-LSTM+CRF方法逐渐成为主流，本文重点在文本分类，就不展开了。</p>
<p>而停止词是文本中一些高频的代词连词介词等对文本分类无意义的词，通常维护一个停用词表，特征提取过程中删除停用表中出现的词，本质上属于特征选择的一部分。</p>
<p>经过文本分词和去停止词之后淘宝商品示例的标题将变成下面的形式：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">夏装 / 雪纺 / 条纹 / 短袖 / t恤 / 女 / 春 / 半袖 / 衣服 / 夏天 / 中长款 / 大码 / 胖mm / 显瘦 / 上衣 / 夏</span><br></pre></td></tr></table></figure>
<ul>
<li>文本表示和特征提取  </li>
</ul>
<p>文本表示：  </p>
<p>文本表示的目的是把文本预处理后的转换成计算机可理解的方式，是决定文本分类质量最重要的部分。传统做法常用词袋模型（BOW, Bag Of Words）或向量空间模型（Vector Space Model），最大的不足是忽略文本上下文关系，每个词之间彼此独立，并且无法表征语义信息。词袋模型的示例如下：( 0, 0, 0, 0, …. , 1, … 0, 0, 0, 0)  </p>
<p>一般来说，词库量至少是百万级别，因此词袋模型将有两个很大的问题：维度高、稀疏性高。词袋模型是向量空间的基础模型，因此向量空间模型通过特征项选择降低维度，通过特征权重计算增加稠密性。  </p>
<p>特征提取：  </p>
<p>向量空间模型的文本表示方法的特征提取对应特征项的选择和特征权重计算两部分。特征选择的基本思路是根据某个评价指标独立的对原始特征项（词项）进行评分排序，从中选择得分最高的一些特征项，过滤掉其余的特征项。常用的评价有文档频率、互信息、信息增益、χ²统计量等。</p>
<p>特征权重主要是经典的TF-IDF方法及其扩展方法，主要思路是一个词的重要度与在类别内的词频成正比，与所有类别出现的次数成反比。</p>
<ul>
<li>基于语义的文本表示</li>
</ul>
<p>传统做法在文本表示方面除了向量空间模型，还有基于语义的文本表示方法，比如LDA主题模型、LSI/PLSI概率潜在语义索引等方法，一般认为这些方法得到的文本表示可以认为文档的深层表示，而 word embedding 文本分布式表示方法则是深度学习方法的重要基础，下文会展现。</p>
<h4 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h4><p>分类器基本都是统计分类方法，基本上大部分机器学习方法都在文本分类领域有所应用，比如朴素贝叶斯分类算法（Naive Bayes）、KNN、SVM、最大熵和神经网络等。</p>
<h3 id="基于深度学习的文本分类方法"><a href="#基于深度学习的文本分类方法" class="headerlink" title="基于深度学习的文本分类方法"></a>基于深度学习的文本分类方法</h3><p>深度学习方法首先是在图像和语音领域取得了巨大的成功，一个很重要的原因就是语音数据是连续而且稠密，有局部相关性。。应用深度学习解决大规模文本分类问题最重要的是解决文本表示，再利用CNN/RNN等网络结构自动获取特征表达能力，去掉繁杂的人工特征工程，端到端的解决问题。  </p>
<ul>
<li>文本的分布式表示：词向量</li>
</ul>
<p>基本思想是将每个词表达成n维稠密、连续的实数向量，与之相对的one-hot encoding向量空间只有一个维度是1，其余都是0。分布式表示最大的优点是具备非常powerful的特征表达能力，比如n维向量每维k个值，可以表征 $k^{n}$个概念。事实上，不管是神经网络的隐层，还是多个潜在变量的概率主题模型，都是应用分布式表示。</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzhd47jnsj30k00bggmm.jpg" width="50%"></p>
<p>这篇文章提出的神经网络语言模型（NNLM，Neural Probabilistic Language Model）采用的是文本分布式表示，即每个词表示为稠密的实数向量。NNLM模型的目标是构建语言模型：</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzhj51cllj30k0011t8v.jpg" width="60%"></p>
<p>词的分布式表示即词向量（word embedding）是训练语言模型的一个附加产物，即图中的Matrix C。</p>
<p>尽管Hinton 86年就提出了词的分布式表示，Bengio 03年便提出了NNLM，词向量真正火起来是google Mikolov 13年发表的两篇word2vec的文章Efficient Estimation of Word Representations in Vector Space和Distributed Representations of Words and Phrases and their Compositionality，更重要的是发布了简单好用的word2vec工具包，在语义维度上得到了很好的验证，极大的推进了文本分析的进程。下图是文中提出的CBOW 和 Skip-Gram两个模型的结构，基本类似于NNLM，不同的是模型去掉了非线性隐层，预测目标不同，CBOW是上下文词预测当前词，Skip-Gram则相反。</p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzhmjh39rj313g0gy3zq.jpg" width="50%"> </p>
<p>除此之外，提出了Hierarchical Softmax和Negative Sample两个方法，很好的解决了计算有效性，事实上这两个方法都没有严格的理论证明，有些trick之处，非常的实用主义。 </p>
<p>注意：实际上word2vec学习的向量和真实语义还是有差距的，更多学到的是具备相似上下文的词。比如good和bad相似度很高，反而是文本分类任务中输入有监督的语义能够学到更多的语义表示。</p>
<p>至此，文本的表示通过词向量的表示方式，把文本数据从高纬度高稀疏的神经网络难处理的方式，变成了类似图像、语音的的连续稠密数据。深度学习算法本身有很强的数据迁移性，很多之前在图像领域很适用的深度学习算法比如CNN等也可以很好的迁移到文本领域了。</p>
<ul>
<li>深度学习文本分类模型</li>
</ul>
<p>词向量解决了文本表示的问题，该部分介绍的文本分类模型则是利用CNN/RNN等深度学习网络及其变体解决自动特征提取（即特征表达）的问题。</p>
<h4 id="fastText"><a href="#fastText" class="headerlink" title="fastText"></a>fastText</h4><p>把fastText放在第一位并非因为它是文本分类的主流做法，而是它极致简单，模型图见下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzhw924n3j30k00a5dg1.jpg" width="50%"></p>
<p>原理是把句子中所有的词向量进行平均（某种意义上可以理解为只有一个avg pooling特殊CNN），然后直接接softmax层。其实文章也加入了一些n-gram特征的trick 来捕获局部序列信息。</p>
<h4 id="TextCNN"><a href="#TextCNN" class="headerlink" title="TextCNN"></a>TextCNN</h4><p>CNN的核心就是捕捉局部相关性，具体到文本分类任务中可以利用CNN来提取句子中类似n-gram的关键信息。  </p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzic7am5vj30k007kaaz.jpg" width="50%"></p>
<p>TextCNN的详细过程原理图见下：</p>
<p><img src="https://ws1.sinaimg.cn/large/006tNbRwgy1fwzihtrtraj30k00jlwgo.jpg" width="60%"></p>
<p>TextCNN的详细过程：  </p>
<p>第一层是图中最左边的7乘5的句子矩阵，每行是词向量，维度=5，这个可以类比为图像中的原始像素点了。然后经过有 filter_size=(2,3,4) 的一维卷积层，每个filter_size 有两个输出 channel。第三层是一个1-max pooling层，这样不同长度句子经过pooling层之后都能变成定长的表示了，最后接一层全连接的 softmax 层，输出每个类别的概率。</p>
<p>特征：  </p>
<p>这里的特征就是词向量，有静态(static)和非静态(non-static)两种方式。比如word2vec预训练的词向量，训练过程不更新词向量，实质上属于迁移学习了，特别是数据量比较小的情况下，采用静态的词向量往往效果不错。non-static则是在训练过程中更新词向量。推荐的方式是 non-static 中的 fine-tunning方式，它是以预训练（pre-train）的word2vec向量初始化词向量，训练过程中调整词向量，能加速收敛，当然如果有充足的训练数据和资源，直接随机初始化词向量效果也是可以的。</p>
<p>通道(Channels)：</p>
<p>图像中可以利用 (R, G, B) 作为不同channel，而文本的输入的channel通常是不同方式的embedding方式（比如word2vec或Glove），实践中也有利用静态词向量和fine-tunning词向量作为不同channel的做法。</p>
<p>一维卷积（conv-1d）：  </p>
<p>图像是二维数据，经过词向量表达的文本为一维数据，因此在TextCNN卷积用的是一维卷积。一维卷积带来的问题是需要设计通过不同 filter_size 的 filter 获取不同宽度的视野。</p>
<p>Pooling层：  </p>
<p>利用CNN解决文本分类问题的文章还是很多的，比如这篇 A Convolutional Neural Network for Modelling Sentences 最有意思的输入是在 pooling 改成 (dynamic) k-max pooling，pooling阶段保留k个最大的信息，保留了全局的序列信息。</p>
<p>举个例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“ 我觉得这个地方景色还不错，但是人也实在太多了 ”</span><br></pre></td></tr></table></figure></p>
<p>虽然前半部分体现的情感是正向的，全局文本表达的偏负面的情感，利用k-max pooling能够很好捕捉这类信息。</p>
<h4 id="TextRNN"><a href="#TextRNN" class="headerlink" title="TextRNN"></a>TextRNN</h4><p>尽管TextCNN能够在很多任务里面能有不错的表现，但CNN有个最大问题是固定 filter_size 的视野，一方面无法建模更长的序列信息，另一方面 filter_size 的超参调节也很繁琐。CNN本质是做文本的特征表达工作，而自然语言处理中更常用的是递归神经网络（RNN, Recurrent Neural Network），能够更好的表达上下文信息。具体在文本分类任务中，Bi-directional RNN（实际使用的是双向LSTM）从某种意义上可以理解为可以捕获变长且双向的的 “n-gram” 信息。</p>
<p>RNN算是在自然语言处理领域非常一个标配网络了，在序列标注/命名体识别/seq2seq模型等很多场景都有应用。下面给出了LSTM用于网络结构原理示意图，在图中，利用最后一个词的输出结果直接接全连接层softmax进行输出。  </p>
<p><img src="https://ws3.sinaimg.cn/large/006tNbRwgy1fwzjocq0vxj30k0069aak.jpg" width="50%"></p>
<h4 id="TextRCNN-TextRNN-CNN"><a href="#TextRCNN-TextRNN-CNN" class="headerlink" title="TextRCNN (TextRNN + CNN)"></a>TextRCNN (TextRNN + CNN)</h4><p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzjrgsojaj30k007utaa.jpg" width="60%"></p>
<p>利用前向和后向RNN得到每个单词的前向和后向上下文的表示：  </p>
<p><img src="https://ws4.sinaimg.cn/large/006tNbRwgy1fwzjss4c6fj30k0020mxe.jpg" width="60%">  </p>
<p>这样词的表示就变成词向量和前向后向上下文向量concat起来的形式了，即：  </p>
<p><img src="https://ws2.sinaimg.cn/large/006tNbRwgy1fwzjtvcxrkj30k000w0sq.jpg" width="60%"></p>
<p>最后再接入跟TextCNN相同的卷积层，pooling层即可，唯一不同的是卷积层filter_size = 1就可以了，不再需要更大 filter_size 获得更大视野，这里词的表示也可以只用双向RNN输出。</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/深度学习/" rel="tag"><i class="fa fa-tag"></i>深度学习</a>
          
            <a href="/tags/自然语言处理/" rel="tag"><i class="fa fa-tag"></i>自然语言处理</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/10/19/生成模型与判别模型/" rel="next" title="生成模型与判别模型">
                <i class="fa fa-chevron-left"></i> 生成模型与判别模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/11/26/Attention-is-All-You-Need/" rel="prev" title="Attention is All You Need">
                Attention is All You Need <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zNzIwOC8xMzc0Mg=="></div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/nice.jpg"
                alt="super1peng" />
            
              <p class="site-author-name" itemprop="name">super1peng</p>
              <p class="site-description motion-element" itemprop="description">享受生活</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">36</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/super1peng" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:super1peng@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          
<div id="music163player">
    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=30 height=86 src="//music.163.com/outchain/player?type=2&id=28815250&auto=1&height=66"></iframe>
</div>
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#用深度学习来解决大规模文本分类问题"><span class="nav-number">1.</span> <span class="nav-text">用深度学习来解决大规模文本分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#具体业务场景"><span class="nav-number">1.1.</span> <span class="nav-text">具体业务场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#传统的文本分类问题"><span class="nav-number">1.2.</span> <span class="nav-text">传统的文本分类问题</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#特征工程"><span class="nav-number">1.2.1.</span> <span class="nav-text">特征工程</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#分类器"><span class="nav-number">1.2.2.</span> <span class="nav-text">分类器</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于深度学习的文本分类方法"><span class="nav-number">1.3.</span> <span class="nav-text">基于深度学习的文本分类方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#fastText"><span class="nav-number">1.3.1.</span> <span class="nav-text">fastText</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TextCNN"><span class="nav-number">1.3.2.</span> <span class="nav-text">TextCNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TextRNN"><span class="nav-number">1.3.3.</span> <span class="nav-text">TextRNN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#TextRCNN-TextRNN-CNN"><span class="nav-number">1.3.4.</span> <span class="nav-text">TextRCNN (TextRNN + CNN)</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-child"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">super1peng</span>

  
</div>










<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i> 访问人数
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i> 总访问量
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  


  <!-- 页面点击小红心 -->
  <script type="text/javascript" src="/js/src/love.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
